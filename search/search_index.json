{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the NannyML Cloud SDK Docs","text":"<p>This page provides an API reference for the NannyML Cloud SDK, generated directly from the code. For tutorials and guides, please refer to our gitbook pages.</p>"},{"location":"#install-nannyml-cloud-sdk","title":"Install NannyML Cloud SDK","text":"<p>The nannyml-cloud-sdk package is available on PyPi and can be installed using your favorite package manager. </p>"},{"location":"#compatibility","title":"Compatibility","text":"<p>You can check which SDK version support which NannyML Cloud versions over on the dedicated cloud documentation page.</p>"},{"location":"#authentication","title":"Authentication","text":"<p>To use the NannyML Cloud SDK you need to provide the URL of your NannyML Cloud instance and an API token to authenticate. You can obtain an API token on the settings page of your NannyML Cloud instance.</p> <p>In code:</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\n\nnml_sdk.url = \"https://beta.app.nannyml.com\"\nnml_sdk.api_token = r\"api token goes here\"\n</code></pre> <p>Using environment variables:</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\nimport os\n\nnml_sdk.url = os.environ['NML_SDK_URL']\nnml_sdk.api_token = os.environ['NML_SDK_API_TOKEN']\n</code></pre> <p>Note</p> <p>We recommend using an environment variable for the API token. This prevents accidentally leaking any token associated with your personal account when sharing code.</p>"},{"location":"#examples","title":"Examples","text":""},{"location":"#model-monitoring","title":"Model monitoring","text":"<p>This snippet provides an example of how you can create a model in NannyML Cloud to start monitoring it.</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\nimport os\nimport pandas as pd\n\nnml_sdk.url = os.environ['NML_SDK_URL']\nnml_sdk.api_token = os.environ['NML_SDK_API_TOKEN']\n\n# Load a NannyML binary classification dataset to use as example\nreference_data = pd.read_csv('https://github.com/NannyML/nannyml/raw/main/nannyml/datasets/data/synthetic_sample_reference.csv')\nanalysis_data = pd.read_csv('https://github.com/NannyML/nannyml/raw/main/nannyml/datasets/data/synthetic_sample_analysis.csv')\ntarget_data = pd.read_csv('https://github.com/NannyML/nannyml/raw/main/nannyml/datasets/data/synthetic_sample_analysis_gt.csv')\nprint(reference_data.head())\n\n# Inspect schema from dataset and apply overrides\nschema = nml_sdk.monitoring.Schema.from_df(\n    'BINARY_CLASSIFICATION',\n    reference_data,\n    target_column_name='work_home_actual',\n    ignore_column_names=('period'),\n)\n\n# Create model\nmodel = nml_sdk.monitoring.Model.create(\n    name='Example model',\n    schema=schema,\n    chunk_period='MONTHLY',\n    reference_data=reference_data,\n    analysis_data=analysis_data,\n    target_data=target_data,\n    key_performance_metric='F1',\n)\n\n# Tweak some settings\nconfig = nml_sdk.monitoring.RuntimeConfiguration.get(model['id'])\nconfig.performance_metric('ACCURACY').enable_realized().enable_estimated()\nconfig.performance_metric('ROC_AUC').set_threshold(threshold_type='CONSTANT', lower=0.7, upper=0.9)\nconfig.univariate_drift_method('WASSERSTEIN').enable_targets()\n\nnml_sdk.monitoring.RuntimeConfiguration.set(model['id'], config)\n\nprint(\"Model\", model['id'], \"created at\", model['createdAt'])\n\n# Start running the model\nnml_sdk.monitoring.Run.trigger(model['id'])\n</code></pre> <p>Note</p> <p>The reference dataset is inspected to determine the model schema. NannyML Cloud uses heuristics to automatically identify most columns, but some columns may not be automatically identified. In this case the target column is not identified, so we manually define <code>work_home_actual</code> as the target column.</p> <p>Once a model has been set up in NannyML Cloud, you could use the snippet below to add more data and ensure continuous monitoring of your model.</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\nimport os\nimport pandas as pd\n\nnml_sdk.url = os.environ['NML_SDK_URL']\nnml_sdk.api_token = os.environ['NML_SDK_API_TOKEN']\n\n# Find model in NannyML Cloud by name\nmodel, = nml_sdk.monitoring.Model.list(name='Example model')\n\n# Add new inferences to NannyML Cloud\nnew_inferences = pd.DataFrame()\nnml_sdk.monitoring.Model.add_analysis_data(model['id'], new_inferences)\n\n# If you have delayed access to ground truth, you can add them to NannyML Cloud\n# later. This will match analysis &amp; target datasets using an identifier column.\ndelayed_ground_truth = pd.DataFrame()\nnml_sdk.monitoring.Model.add_analysis_target_data(model['id'], delayed_ground_truth)\n\n# Trigger analysis of the new data\nnml_sdk.monitoring.Run.trigger(model['id'])\n</code></pre>"},{"location":"#model-evaluation","title":"Model evaluation","text":"<p>This snippet provides an example of how you can set up model evaluation in NannyML Cloud.</p> <p>You can configure each of the available performance metrics by providing an optional value for ROPE and HDI width. If a <code>None</code> is provided, NannyML will calculate a sensible default during the first evaluation run.</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\nimport os\nimport pandas as pd\n\nnml_sdk.url = os.environ['NML_SDK_URL']\nnml_sdk.api_token = os.environ['NML_SDK_API_TOKEN']\n\n# Load a NannyML binary classification dataset to use as example\nreference_data = pd.read_csv('https://github.com/NannyML/nannyml/raw/main/nannyml/datasets/data/synthetic_car_loan_reference.csv')\nanalysis_data = pd.read_csv('https://github.com/NannyML/nannyml/raw/main/nannyml/datasets/data/synthetic_car_loan_analysis.csv')\ntarget_data = pd.read_csv('https://github.com/NannyML/nannyml/raw/main/nannyml/datasets/data/synthetic_car_loan_analysis_target.csv')\n\n# The evaluation data will be a combination of analysis and target datasets. We'll only use the first 1000 rows for now.\nevaluation_data = analysis_data.merge(target_data, on='id').head(1000)\n\nprint(reference_data.head())\n\n# Inspect schema from dataset and apply overrides\nschema = nml_sdk.model_evaluation.Schema.from_df(\n    'BINARY_CLASSIFICATION',\n    reference_data,\n    target_column_name='repaid',\n)\n\n# Create model\nmodel = nml_sdk.model_evaluation.Model.create(\n    name='from_sdk',\n    schema=schema,\n    reference_data=reference_data,\n    evaluation_data=evaluation_data,\n    metrics_configuration={\n        'F1': {\n            'enabled': True,\n            'rope_lower_bound': 0.8,\n            'rope_upper_bound': 0.9,\n            'hdi_width': 0.01\n        },\n        'ACCURACY': {\n            'enabled': True,\n            'rope_lower_bound': None,\n            'rope_upper_bound': None,\n            'hdi_width': None\n        },\n    },\n    key_performance_metric='F1',\n    hypothesis='MODEL_PERFORMANCE_NO_WORSE_THAN_REFERENCE',\n    classification_threshold=0.5,\n)\nprint(\"Model\", model['id'], \"created at\", model['createdAt'])\n\n# Now trigger the model evaluation run with our first 1000 rows of evaluation data\n\nnml_sdk.model_evaluation.Run.trigger(model['id'])\n</code></pre> <p>Now we'll add the next set of evaluation data and trigger another evaluation run.</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\nimport os\nimport pandas as pd\n\nevaluation_data = analysis_data.join(target_data, on='id').iloc[1000:2000]\n\n# Retrieve the model that was created earlier, using the name as a filter.\nmodel, = nml_sdk.model_evaluation.Model.list(name='from_sdk')\nprint(model)\n\n# Adding the new evaluation data to the model\nnml_sdk.model_evaluation.Model.add_evaluation_data(model_id=model['id'], data=evaluation_data)\n\n# Trigger the model evaluation run to include the latest set of evaluation data\nnml_sdk.model_evaluation.Run.trigger(model['id'])\n</code></pre>"},{"location":"#experiments","title":"Experiments","text":"<p>This snippet provides an example of how you can set up an A/B-testing experiment in NannyML Cloud.</p> <p>You can configure each of the available metrics by providing a value for ROPE and HDI width.</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\nfrom pprint import pprint\nimport pandas as pd\nimport os\n\nnml_sdk.url = os.environ['NML_SDK_URL']\nnml_sdk.api_token = os.environ['NML_SDK_API_TOKEN']\n\nexperiment_data = pd.DataFrame({\n    'variable': ['RJ45', 'RJ45', 'FOO', 'FOO'],\n    'group': ['control', 'treatment', 'control', 'treatment'],\n    'success_count': [50, 30, 25, 10],\n    'fail_count': [1, 2, 2, 0],\n    'random': [1, 2, 5, 7],\n})\n\nmetrics = list(experiment_data['variable'].unique())\n\nschema = nml_sdk.experiment.Schema.from_df(df=experiment_data, metric_column_name='variable')\npprint(schema)\n\nexperiment = nml_sdk.experiment.Experiment.create(\n    name='experiment (SDK)',\n    schema=schema,\n    experiment_type='A_B_TESTING',\n    experiment_data=experiment_data,\n    key_experiment_metric='renewed',\n    metrics_configuration={\n        metric: {\n            \"rope_lower_bound\": 0.80,\n            \"rope_upper_bound\": 0.90,\n            \"hdi_width\": 0.01,\n            \"enabled\": True,\n        } for metric in metrics\n    }\n)\npprint(experiment)\n\nnml_sdk.experiment.Run.trigger(experiment['id'])\n</code></pre> <p>Now we'll add the next set of experiment data and trigger another evaluation run.</p> <pre><code>import nannyml_cloud_sdk as nml_sdk\nimport os\nimport pandas as pd\n\nnml_sdk.url = os.environ['NML_SDK_URL']\nnml_sdk.api_token = os.environ['NML_SDK_API_TOKEN']\n\nexperiment_data = pd.DataFrame({\n    'variable': ['RJ45', 'RJ45', 'FOO', 'FOO'],\n    'group': ['control', 'treatment', 'control', 'treatment'],\n    'success_count': [27, 35, 19, 31],\n    'fail_count': [1, 5, 12, 12],\n    'random': [1, 2, 5, 7],\n})\n\nexperiment, = nml_sdk.experiment.Experiment.list(name='experiment (SDK)')\n\nnml_sdk.experiment.Experiment.add_experiment_data(experiment['id'], experiment_data)\n\nnml_sdk.experiment.Run.trigger(experiment['id'])\n</code></pre>"},{"location":"api_reference/client/","title":"client","text":""},{"location":"api_reference/client/#nannyml_cloud_sdk.client.execute","title":"execute  <code>module-attribute</code>","text":"<pre><code>execute = _translate_gql_errors(execute)\n</code></pre> <p>Execute query against the configured NannyML Cloud GraphQL API.</p> <p>Raises:</p> Type Description <code>ApiError</code> <p>If the GraphQL query fails.</p>"},{"location":"api_reference/client/#nannyml_cloud_sdk.client.get_client","title":"get_client","text":"<pre><code>get_client() -&gt; Client\n</code></pre> <p>Get the active GraphQL client or create a new one if none exists</p>"},{"location":"api_reference/data/","title":"data","text":""},{"location":"api_reference/data/#nannyml_cloud_sdk.data.ColumnDetails","title":"ColumnDetails","text":"<p>               Bases: <code>TypedDict</code></p> <p>Details about a column in a model schema.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the column.</p> <code>columnType</code> <code>ColumnType</code> <p>The type of the column.</p> <code>dataType</code> <code>str</code> <p>The data type of the column.</p> <code>className</code> <code>Optional[str]</code> <p>Class name for prediction columns in a multiclass classification problem.</p>"},{"location":"api_reference/data/#nannyml_cloud_sdk.data.Data","title":"Data","text":""},{"location":"api_reference/data/#nannyml_cloud_sdk.data.Data.upload","title":"upload  <code>classmethod</code>","text":"<pre><code>upload(df: pd.DataFrame) -&gt; StorageInfo\n</code></pre> <p>Upload a pandas dataframe to NannyML Cloud</p> <p>Returns:</p> Name Type Description <code>str</code> <code>StorageInfo</code> <p>The ID of the uploaded dataset</p>"},{"location":"api_reference/data/#nannyml_cloud_sdk.data.StorageInfo","title":"StorageInfo","text":"<p>               Bases: <code>TypedDict</code></p> <p>Storage info for data.</p> <p>NannyML Cloud accepts data from various sources. This type describes the different storage info types that can be used to specify the location of the data. Only one of the storage info types should be provided.</p> <p>Attributes:</p> Name Type Description <code>raw</code> <code>Optional[StorageInfoRaw]</code> <p>Storage info for <code>fsspec</code> compatible input, e.g. public link.</p> <code>azure</code> <code>Optional[StorageInfoAzureBlob]</code> <p>Storage info for Azure Blob Storage.</p> <code>s3</code> <code>Optional[StorageInfoS3]</code> <p>Storage info for Amazon S3.</p> <code>cache</code> <code>Optional[StorageInfoCache]</code> <p>Storage info for cached data.</p>"},{"location":"api_reference/data/#nannyml_cloud_sdk.data.StorageInfoAzureBlob","title":"StorageInfoAzureBlob","text":"<p>               Bases: <code>TypedDict</code></p> <p>Storage info for Azure Blob Storage.</p> <p>Attributes:</p> Name Type Description <code>accountName</code> <code>str</code> <p>The name of the storage account.</p> <code>container</code> <code>str</code> <p>The name of the container.</p> <code>path</code> <code>str</code> <p>The path to the data within the container.</p> <code>isPublic</code> <code>bool</code> <p>Whether the data is publicly accessible.</p> <code>accountKey</code> <code>Optional[str]</code> <p>The account key for the storage account. Should only be provided when using account key to authenticate.</p> <code>sasToken</code> <code>Optional[str]</code> <p>The SAS (Shared Access Signature) token for the storage account. Should only be provided when using a SAS token to authenticate.</p>"},{"location":"api_reference/data/#nannyml_cloud_sdk.data.StorageInfoCache","title":"StorageInfoCache","text":"<p>               Bases: <code>TypedDict</code></p> <p>Storage info for cached data.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The ID of the cached dataset. This ID is generated by the NannyML Cloud server when uploading data using Data.upload.</p>"},{"location":"api_reference/data/#nannyml_cloud_sdk.data.StorageInfoRaw","title":"StorageInfoRaw","text":"<p>               Bases: <code>TypedDict</code></p> <p>Storage info for <code>fsspec</code> compatible input, e.g. public link.</p> <p>Attributes:</p> Name Type Description <code>connectionString</code> <code>str</code> <p>The connection string for the storage backend.</p> <code>options</code> <code>Dict[str, Any]</code> <p>Additional options for the storage backend.</p>"},{"location":"api_reference/data/#nannyml_cloud_sdk.data.StorageInfoS3","title":"StorageInfoS3","text":"<p>               Bases: <code>TypedDict</code></p> <p>Storage info for Amazon S3.</p> <p>Attributes:</p> Name Type Description <code>uri</code> <code>str</code> <p>The S3 URI for the data, e.g. <code>s3://bucket/data.csv</code>.</p> <code>authenticationMode</code> <code>S3AuthenticationMode</code> <p>The authentication mode to use.</p> <code>awsAccessKeyId</code> <code>Optional[str]</code> <p>ID for the access key. Should only be provided when using access key to authenticate.</p> <code>awsSecretAccessKey</code> <code>Optional[str]</code> <p>Secret for the access key. Should only be provided when using access key to authenticate.</p>"},{"location":"api_reference/enums/","title":"enums","text":""},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.ChunkPeriod","title":"ChunkPeriod  <code>module-attribute</code>","text":"<pre><code>ChunkPeriod = Literal['YEARLY', 'QUARTERLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY']\n</code></pre> <p>Time periods for chunking supported by NannyML Cloud.</p>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.ColumnType","title":"ColumnType  <code>module-attribute</code>","text":"<pre><code>ColumnType = Literal['TARGET', 'PREDICTION_SCORE', 'PREDICTION', 'TIMESTAMP', 'CATEGORICAL_FEATURE', 'CONTINUOUS_FEATURE', 'IGNORED', 'IDENTIFIER', 'METRIC_NAME', 'GROUP_NAME', 'SUCCESS_COUNT', 'FAIL_COUNT']\n</code></pre> <p>Schema column types defined by NannyML Cloud.</p>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.DataSourceEventType","title":"DataSourceEventType  <code>module-attribute</code>","text":"<pre><code>DataSourceEventType = Literal['CREATED', 'DATA_ADDED', 'DATA_REMOVED', 'DATA_UPDATED']\n</code></pre> <p>Events recorded for model data sources.</p>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.FeatureType","title":"FeatureType  <code>module-attribute</code>","text":"<pre><code>FeatureType = Literal['CONTINUOUS', 'CATEGORY']\n</code></pre> <p>Feature types supported by NannyML Cloud.</p>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.PerformanceMetric","title":"PerformanceMetric  <code>module-attribute</code>","text":"<pre><code>PerformanceMetric = Literal['ROC_AUC', 'F1', 'PRECISION', 'RECALL', 'SPECIFICITY', 'ACCURACY', 'CONFUSION_MATRIX', 'BUSINESS_VALUE', 'MAE', 'MAPE', 'MSE', 'RMSE', 'MSLE', 'RMSLE']\n</code></pre> <p>Performance metrics supported by NannyML Cloud.</p>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.ProblemType","title":"ProblemType  <code>module-attribute</code>","text":"<pre><code>ProblemType = Literal['BINARY_CLASSIFICATION', 'MULTICLASS_CLASSIFICATION', 'REGRESSION']\n</code></pre> <p>Problem types supported by NannyML Cloud.</p>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.ProductType","title":"ProductType  <code>module-attribute</code>","text":"<pre><code>ProductType = Literal['MONITORING', 'EVALUATION', 'EXPERIMENT']\n</code></pre> <p>Product modules of NannyML Cloud</p>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.RunState","title":"RunState  <code>module-attribute</code>","text":"<pre><code>RunState = Literal['SCHEDULED', 'RUNNING', 'CANCELLING', 'COMPLETED']\n</code></pre> <p>States a NannyML run can be in.</p> <ul> <li><code>SCHEDULED</code>: The run is scheduled to start at a later time.</li> <li><code>RUNNING</code>: The run is currently active.</li> <li><code>CANCELLING</code>: The run is currently being cancelled.</li> <li><code>COMPLETED</code>: The run has completed (successfully or unsuccessfully).</li> </ul>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.S3AuthenticationMode","title":"S3AuthenticationMode  <code>module-attribute</code>","text":"<pre><code>S3AuthenticationMode = Literal['ANONYMOUS', 'INTEGRATED', 'ACCESS_KEY']\n</code></pre> <p>Authentication modes for S3 access supported by NannyML Cloud.</p> <ul> <li><code>ANONYMOUS</code>: No authentication required.</li> <li><code>INTEGRATED</code>: Use the service account permissions the NannyML Cloud server has to access S3.</li> <li><code>ACCESS_KEY</code>: Provide access key ID and secret to access S3.</li> </ul>"},{"location":"api_reference/enums/#nannyml_cloud_sdk.enums.ThresholdType","title":"ThresholdType  <code>module-attribute</code>","text":"<pre><code>ThresholdType = Literal['CONSTANT', 'STANDARD_DEVIATION']\n</code></pre> <p>Threshold types supported by NannyML Cloud.</p>"},{"location":"api_reference/errors/","title":"errors","text":""},{"location":"api_reference/errors/#nannyml_cloud_sdk.errors.ApiError","title":"ApiError","text":"<p>               Bases: <code>SdkError</code></p> <p>Raised when the NannyML Cloud API returns an error</p>"},{"location":"api_reference/errors/#nannyml_cloud_sdk.errors.InvalidOperationError","title":"InvalidOperationError","text":"<p>               Bases: <code>SdkError</code></p> <p>Raised when attempting an invalid operation</p>"},{"location":"api_reference/errors/#nannyml_cloud_sdk.errors.LicenseError","title":"LicenseError","text":"<p>               Bases: <code>SdkError</code></p> <p>Raised when the NannyML Cloud API returns a license error</p>"},{"location":"api_reference/errors/#nannyml_cloud_sdk.errors.SdkError","title":"SdkError","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for all exceptions raised from the NannyML Cloud SDK</p>"},{"location":"api_reference/schema/","title":"schema","text":""},{"location":"api_reference/schema/#nannyml_cloud_sdk.schema.normalize","title":"normalize","text":"<pre><code>normalize(column_name: str) -&gt; str\n</code></pre> <p>Normalize a column name.</p>"},{"location":"api_reference/summary/","title":"Summary","text":"<ul> <li>client</li> <li>data</li> <li>enums</li> <li>errors</li> <li>experiment<ul> <li>enums</li> <li>experiment</li> <li>run</li> <li>schema</li> </ul> </li> <li>model_evaluation<ul> <li>enums</li> <li>model</li> <li>run</li> <li>schema</li> </ul> </li> <li>monitoring<ul> <li>configuration</li> <li>custom_metric</li> <li>enums</li> <li>model</li> <li>run</li> <li>schema</li> </ul> </li> <li>schema</li> </ul>"},{"location":"api_reference/experiment/enums/","title":"enums","text":""},{"location":"api_reference/experiment/enums/#nannyml_cloud_sdk.experiment.enums.ExperimentType","title":"ExperimentType  <code>module-attribute</code>","text":"<pre><code>ExperimentType = Literal['A_B_TESTING']\n</code></pre> <p>Experiment types supported by NannyML Cloud.</p>"},{"location":"api_reference/experiment/experiment/","title":"experiment","text":""},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment","title":"Experiment","text":""},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment.add_experiment_data","title":"add_experiment_data  <code>classmethod</code>","text":"<pre><code>add_experiment_data(experiment_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add evaluation data to an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>ID of the experiment.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added.</p> required Note <p>This method does not update existing data. It only adds new data. If you want to update existing data, use upsert_data instead.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(name: str, schema: ExperimentSchema, experiment_data: pd.DataFrame, experiment_type: ExperimentType, metrics_configuration: Dict[str, MetricConfiguration], key_experiment_metric: Optional[str] = None) -&gt; ExperimentDetails\n</code></pre> <p>Create a new experiment.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the experiment.</p> required <code>schema</code> <code>ExperimentSchema</code> <p>Schema of the experiment. Typically, created using Schema.from_df.</p> required <code>experiment_data</code> <code>DataFrame</code> <p>Data to be used for the experiment.</p> required <code>experiment_type</code> <code>ExperimentType</code> <p>Type of the experiment.</p> required <code>metrics_configuration</code> <code>Dict[str, MetricConfiguration]</code> <p>Configuration for each metric to be used in the experiment.</p> required <code>key_experiment_metric</code> <code>Optional[str]</code> <p>Optional metric to be used as the key experiment metric.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExperimentDetails</code> <p>Detailed about the experiment once it has been created.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment.delete","title":"delete  <code>classmethod</code>","text":"<pre><code>delete(experiment_id: str) -&gt; None\n</code></pre> <p>Delete an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>ID of the experiment to delete.</p> required"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(experiment_id: str) -&gt; ExperimentDetails\n</code></pre> <p>Get details for an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>ID of the experiment to get details for.</p> required <p>Returns:</p> Type Description <code>ExperimentDetails</code> <p>Detailed information about the experiment.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment.get_data_history","title":"get_data_history  <code>classmethod</code>","text":"<pre><code>get_data_history(experiment_id: str) -&gt; List[DataSourceEvent]\n</code></pre> <p>Get the data history for an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>ID of the experiment.</p> required <p>Returns:</p> Type Description <code>List[DataSourceEvent]</code> <p>List of events related to reference data for the experiment.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment.list","title":"list  <code>classmethod</code>","text":"<pre><code>list(name: Optional[str] = None, experiment_type: Optional[ExperimentType] = None) -&gt; List[ExperimentSummary]\n</code></pre> <p>List defined experiments.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Optional name filter.</p> <code>None</code> <code>experiment_type</code> <code>Optional[ExperimentType]</code> <p>Optional problem type filter.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[ExperimentSummary]</code> <p>List of models that match the provided filter criteria.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.Experiment.upsert_experiment_data","title":"upsert_experiment_data  <code>classmethod</code>","text":"<pre><code>upsert_experiment_data(experiment_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add or update analysis data for an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>ID of the model.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added/updated.</p> required Note <p>This method compares existing data with the new data to determine which rows to update and which to add. If you are certain you are only adding new data, it is recommended to use add_experiment_data instead for better performance.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.ExperimentDetails","title":"ExperimentDetails","text":"<p>               Bases: <code>ExperimentSummary</code></p> <p>Detailed information about an experiment.</p> <p>Attributes:</p> Name Type Description <code>latestRun</code> <code>Optional[RunSummary]</code> <p>The currently active run or latest run performed for the experiment. This is <code>None</code> if no runs have been performed yet.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.ExperimentSummary","title":"ExperimentSummary","text":"<p>               Bases: <code>TypedDict</code></p> <p>Summary of an experiment.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier of the experiment (generated by NannyML Cloud when an experiment is created).</p> <code>name</code> <code>str</code> <p>User-defined name of the experiment.</p> <code>createdAt</code> <code>datetime</code> <p>Timestamp when the experiment was created.</p>"},{"location":"api_reference/experiment/experiment/#nannyml_cloud_sdk.experiment.experiment.MetricConfiguration","title":"MetricConfiguration","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration for a metric in an experiment.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether the metric is enabled or disabled.</p> <code>rope_lower_bound</code> <code>float</code> <p>Lower bound of the region of practical equivalence (ROPE) for the metric.</p> <code>rope_upper_bound</code> <code>float</code> <p>Upper bound of the region of practical equivalence (ROPE) for the metric.</p> <code>hdi_width</code> <code>float</code> <p>Required width of the highest density interval (HDI) for the metric before evaluating the hypothesis.</p>"},{"location":"api_reference/experiment/run/","title":"run","text":""},{"location":"api_reference/experiment/run/#nannyml_cloud_sdk.experiment.run.Run","title":"Run","text":"<p>Operations for running NannyML experiment analysis.</p>"},{"location":"api_reference/experiment/run/#nannyml_cloud_sdk.experiment.run.Run.trigger","title":"trigger  <code>classmethod</code>","text":"<pre><code>trigger(experiment_id: str) -&gt; RunSummary\n</code></pre> <p>Trigger analysis of new data for an experiment.</p> <p>This method starts analysis for an experiment. The run is scheduled to start immediately, but the function returns before the run has started. The returned summary information can be used to track the progress of the run.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>The ID of the model to run.</p> required <p>Returns:</p> Type Description <code>RunSummary</code> <p>Summary information for the newly started run.</p>"},{"location":"api_reference/experiment/run/#nannyml_cloud_sdk.experiment.run.RunSummary","title":"RunSummary","text":"<p>               Bases: <code>TypedDict</code></p> <p>Summary information for NannyML analysis of an Experiment, a <code>run</code>.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the run (generated by NannyML Cloud).</p> <code>state</code> <code>RunState</code> <p>Current state of the run.</p> <code>scheduledFor</code> <code>Optional[datetime]</code> <p>Date and time the run was scheduled to start.</p> <code>startedAt</code> <code>Optional[datetime]</code> <p>Date and time the run started.</p> <code>completedAt</code> <code>Optional[datetime]</code> <p>Date and time the run completed.</p> <code>ranSuccessfully</code> <code>Optional[bool]</code> <p>Whether the run completed successfully.</p>"},{"location":"api_reference/experiment/schema/","title":"schema","text":""},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.ExperimentSchema","title":"ExperimentSchema","text":"<p>               Bases: <code>BaseSchema</code></p> <p>Schema for a machine learning experiment.</p>"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema","title":"Schema","text":"<p>Operations for working with machine learning experiment schemas.</p>"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema.from_df","title":"from_df  <code>classmethod</code>","text":"<pre><code>from_df(df: pd.DataFrame, metric_column_name: Optional[str] = None, group_column_name: Optional[str] = None, success_count_column_name: Optional[str] = None, fail_count_column_name: Optional[str] = None, identifier_column_name: Optional[str] = None, ignore_column_names: Union[str, Collection[str]] = ()) -&gt; ExperimentSchema\n</code></pre> <p>Create a schema from a pandas dataframe.</p> <p>Sends a sample of the dataframe to the NannyML Cloud API to inspect the schema. Heuristics are used to identify what each column represents. The schema is then modified according to the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The pandas dataframe to create a schema from.</p> required <code>metric_column_name</code> <code>Optional[str]</code> <p>The name of the column containing the metric names.</p> <code>None</code> <code>group_column_name</code> <code>Optional[str]</code> <p>The name of the column containing the group names for each group.</p> <code>None</code> <code>success_count_column_name</code> <code>Optional[str]</code> <p>The name of the column containing the success count for a metric and group.</p> <code>None</code> <code>fail_count_column_name</code> <code>Optional[str]</code> <p>The name of the column containing the fail count for a metric and group.</p> <code>None</code> <code>identifier_column_name</code> <code>Optional[str]</code> <p>The name of the identifier column. Any column that heuristics identified as identifier will be changed to a feature column.</p> <code>None</code> <code>ignore_column_names</code> <code>Union[str, Collection[str]]</code> <p>The names of columns to ignore.</p> <code>()</code> <p>Returns:</p> Type Description <code>ExperimentSchema</code> <p>The inspected schema with any modifications applied.</p>"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema.set_fail_count","title":"set_fail_count  <code>classmethod</code>","text":"<pre><code>set_fail_count(schema: ExperimentSchema, column_name: str) -&gt; ExperimentSchema\n</code></pre> <p>Set the fail count column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ExperimentSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the fail count column. Any column that was previously set as the metric column will be changed to an ignored column.</p> required"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema.set_group_name","title":"set_group_name  <code>classmethod</code>","text":"<pre><code>set_group_name(schema: ExperimentSchema, column_name: str) -&gt; ExperimentSchema\n</code></pre> <p>Set the group name column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ExperimentSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the group name column. Any column that was previously set as the metric column will be changed to an ignored column.</p> required"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema.set_identifier","title":"set_identifier  <code>classmethod</code>","text":"<pre><code>set_identifier(schema: ExperimentSchema, column_name: str) -&gt; ExperimentSchema\n</code></pre> <p>Set the identifier column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ExperimentSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the identifier column. Any column that was previously set as identifier will be changed to a feature column.</p> required <p>Returns:</p> Type Description <code>ExperimentSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema.set_ignored","title":"set_ignored  <code>classmethod</code>","text":"<pre><code>set_ignored(schema: ExperimentSchema, column_names: Union[str, Collection[str]]) -&gt; ExperimentSchema\n</code></pre> <p>Set one or more columns to be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ExperimentSchema</code> <p>The schema to modify.</p> required <code>column_names</code> <code>Union[str, Collection[str]]</code> <p>The name of the column or columns to ignore.</p> required <p>Returns:</p> Type Description <code>ExperimentSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema.set_metric_name","title":"set_metric_name  <code>classmethod</code>","text":"<pre><code>set_metric_name(schema: ExperimentSchema, column_name: str) -&gt; ExperimentSchema\n</code></pre> <p>Set the metric name column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ExperimentSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the metric name column. Any column that was previously set as the metric column will be changed to an ignored column.</p> required"},{"location":"api_reference/experiment/schema/#nannyml_cloud_sdk.experiment.schema.Schema.set_success_count","title":"set_success_count  <code>classmethod</code>","text":"<pre><code>set_success_count(schema: ExperimentSchema, column_name: str) -&gt; ExperimentSchema\n</code></pre> <p>Set the success count column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ExperimentSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the success column. Any column that was previously set as the metric column will be changed to an ignored column.</p> required"},{"location":"api_reference/model_evaluation/enums/","title":"enums","text":""},{"location":"api_reference/model_evaluation/enums/#nannyml_cloud_sdk.model_evaluation.enums.HypothesisType","title":"HypothesisType  <code>module-attribute</code>","text":"<pre><code>HypothesisType = Literal['MODEL_PERFORMANCE_NO_WORSE_THAN_REFERENCE', 'MODEL_PERFORMANCE_WITHIN_RANGE']\n</code></pre> <p>Model evaluation hypotheses supported by NannyML Cloud.</p>"},{"location":"api_reference/model_evaluation/model/","title":"model","text":""},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.MetricConfiguration","title":"MetricConfiguration","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration for a model evaluation metric.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether the metric is enabled or disabled.</p> <code>rope_lower_bound</code> <code>Optional[float]</code> <p>Lower bound of the region of practical equivalence (ROPE) for the metric. This is required when the hypothesis is <code>MODEL_PERFORMANCE_WITHIN_RANGE</code>.</p> <code>rope_upper_bound</code> <code>Optional[float]</code> <p>Upper bound of the region of practical equivalence (ROPE) for the metric. This is required when the hypothesis is <code>MODEL_PERFORMANCE_WITHIN_RANGE</code>.</p> <code>hdi_width</code> <code>Optional[float]</code> <p>Required width of the highest density interval (HDI) for the metric before evaluating the hypothesis.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model","title":"Model","text":""},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.add_evaluation_data","title":"add_evaluation_data  <code>classmethod</code>","text":"<pre><code>add_evaluation_data(model_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add evaluation data to a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added.</p> required Note <p>This method does not update existing data. It only adds new data. If you want to update existing data, use upsert_evaluation_data instead.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(name: str, schema: ModelSchema, reference_data: pd.DataFrame, hypothesis: HypothesisType, classification_threshold: float, metrics_configuration: Dict[PerformanceMetric, MetricConfiguration], key_performance_metric: PerformanceMetric, evaluation_data: Optional[pd.DataFrame] = None) -&gt; ModelDetails\n</code></pre> <p>Create a new model.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the model.</p> required <code>schema</code> <code>ModelSchema</code> <p>Schema of the model. Typically, created using Schema.from_df.</p> required <code>hypothesis</code> <code>HypothesisType</code> <p>The type of hypothesis the model is trying to validate. This can be one of the following: - <code>MODEL_PERFORMANCE_NO_WORSE_THAN_REFERENCE</code>: The model's performance is not worse than the reference. - <code>MODEL_PERFORMANCE_WITHIN_RANGE</code>: The model's performance is within a specified range.</p> required <code>classification_threshold</code> <code>float</code> <p>The threshold used to turn predicted probabilities into binary predictions.</p> required <code>reference_data</code> <code>DataFrame</code> <p>Reference data to use for the model.</p> required <code>evaluation_data</code> <code>Optional[DataFrame]</code> <p>Analysis data to use for the model. If the data contains targets, targets must always be provided together with analysis data.</p> <code>None</code> <code>metrics_configuration</code> <code>Dict[PerformanceMetric, MetricConfiguration]</code> <p>Configuration for each metric to be used in the model.</p> required <code>key_performance_metric</code> <code>PerformanceMetric</code> <p>Key performance metric for the model.</p> required <p>Returns:</p> Type Description <code>ModelDetails</code> <p>Detailed about the model once it has been created.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.delete","title":"delete  <code>classmethod</code>","text":"<pre><code>delete(model_id: str) -&gt; None\n</code></pre> <p>Delete a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model to delete.</p> required"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(model_id: str) -&gt; ModelDetails\n</code></pre> <p>Get details for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model to get details for.</p> required <p>Returns:</p> Type Description <code>ModelDetails</code> <p>Detailed information about the model.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.get_evaluation_data_history","title":"get_evaluation_data_history  <code>classmethod</code>","text":"<pre><code>get_evaluation_data_history(model_id: str) -&gt; List[DataSourceEvent]\n</code></pre> <p>Get evaluation data history for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <p>Returns:</p> Type Description <code>List[DataSourceEvent]</code> <p>List of events related to analysis data for the model.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.get_reference_data_history","title":"get_reference_data_history  <code>classmethod</code>","text":"<pre><code>get_reference_data_history(model_id: str) -&gt; List[DataSourceEvent]\n</code></pre> <p>Get reference data history for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <p>Returns:</p> Type Description <code>List[DataSourceEvent]</code> <p>List of events related to reference data for the model.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.list","title":"list  <code>classmethod</code>","text":"<pre><code>list(name: Optional[str] = None, problem_type: Optional[ProblemType] = None) -&gt; List[ModelSummary]\n</code></pre> <p>List defined models.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Optional name filter.</p> <code>None</code> <code>problem_type</code> <code>Optional[ProblemType]</code> <p>Optional problem type filter.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[ModelSummary]</code> <p>List of models that match the provided filter criteria.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.Model.upsert_evaluation_data","title":"upsert_evaluation_data  <code>classmethod</code>","text":"<pre><code>upsert_evaluation_data(model_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add or update analysis data for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added/updated.</p> required Note <p>This method compares existing data with the new data to determine which rows to update and which to add. If you are certain you are only adding new data, it is recommended to use add_evaluation_data instead for better performance.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.ModelDetails","title":"ModelDetails","text":"<p>               Bases: <code>ModelSummary</code></p> <p>Detailed information about a model.</p> <p>Attributes:</p> Name Type Description <code>latestRun</code> <code>Optional[RunSummary]</code> <p>The currently active run or latest run performed for the model. This is <code>None</code> if no runs have been performed yet.</p>"},{"location":"api_reference/model_evaluation/model/#nannyml_cloud_sdk.model_evaluation.model.ModelSummary","title":"ModelSummary","text":"<p>               Bases: <code>TypedDict</code></p> <p>Summary of a model.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier of the model (generated by NannyML Cloud when a model is created).</p> <code>name</code> <code>str</code> <p>User-defined name of the model.</p> <code>problemType</code> <code>ProblemType</code> <p>Type of problem the model is trying to solve.</p> <code>createdAt</code> <code>datetime</code> <p>Timestamp when the model was created.</p>"},{"location":"api_reference/model_evaluation/run/","title":"run","text":""},{"location":"api_reference/model_evaluation/run/#nannyml_cloud_sdk.model_evaluation.run.Run","title":"Run","text":"<p>Operations for running NannyML model evaluation.</p>"},{"location":"api_reference/model_evaluation/run/#nannyml_cloud_sdk.model_evaluation.run.Run.trigger","title":"trigger  <code>classmethod</code>","text":"<pre><code>trigger(model_id: str) -&gt; RunSummary\n</code></pre> <p>Trigger analysis of new data for a model.</p> <p>This method starts analysis for a model. The run is scheduled to start immediately, but the function returns before the run has started. The returned summary information can be used to track the progress of the run.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>The ID of the model to run.</p> required <p>Returns:</p> Type Description <code>RunSummary</code> <p>Summary information for the newly started run.</p>"},{"location":"api_reference/model_evaluation/run/#nannyml_cloud_sdk.model_evaluation.run.RunSummary","title":"RunSummary","text":"<p>               Bases: <code>TypedDict</code></p> <p>Summary information for NannyML evaluation of a model, a <code>run</code>.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the run (generated by NannyML Cloud).</p> <code>state</code> <code>RunState</code> <p>Current state of the run.</p> <code>scheduledFor</code> <code>Optional[datetime]</code> <p>Date and time the run was scheduled to start.</p> <code>startedAt</code> <code>Optional[datetime]</code> <p>Date and time the run started.</p> <code>completedAt</code> <code>Optional[datetime]</code> <p>Date and time the run completed.</p> <code>ranSuccessfully</code> <code>Optional[bool]</code> <p>Whether the run completed successfully.</p>"},{"location":"api_reference/model_evaluation/schema/","title":"schema","text":""},{"location":"api_reference/model_evaluation/schema/#nannyml_cloud_sdk.model_evaluation.schema.ModelSchema","title":"ModelSchema","text":"<p>               Bases: <code>BaseSchema</code></p> <p>Schema for a machine learning model.</p>"},{"location":"api_reference/model_evaluation/schema/#nannyml_cloud_sdk.model_evaluation.schema.Schema","title":"Schema","text":"<p>Operations for working with machine learning model schemas.</p>"},{"location":"api_reference/model_evaluation/schema/#nannyml_cloud_sdk.model_evaluation.schema.Schema.from_df","title":"from_df  <code>classmethod</code>","text":"<pre><code>from_df(problem_type: ProblemType, df: pd.DataFrame, target_column_name: Optional[str] = None, prediction_score_column_name_or_mapping: Optional[Union[str, Dict[str, str]]] = None, identifier_column_name: Optional[str] = None, ignore_column_names: Union[str, Collection[str]] = ()) -&gt; ModelSchema\n</code></pre> <p>Create a schema from a pandas dataframe.</p> <p>Sends a sample of the dataframe to the NannyML Cloud API to inspect the schema. Heuristics are used to identify what each column represents. The schema is then modified according to the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>problem_type</code> <code>ProblemType</code> <p>The problem type of the model.</p> required <code>df</code> <code>DataFrame</code> <p>The pandas dataframe to create a schema from.</p> required <code>target_column_name</code> <code>Optional[str]</code> <p>The name of the target column. Any column that heuristics identified as target will be changed to a feature column.</p> <code>None</code> <code>prediction_score_column_name_or_mapping</code> <code>Optional[Union[str, Dict[str, str]]]</code> <p>This parameter accepts two formats depending on problem type.</p> <ul> <li>For binary classification and regression, this should be the name of the prediction score column.</li> <li>For multiclass classification, it should be a dict mapping prediction score column names to class   names, e.g. <code>{'prediction_score_1': 'class_1', 'prediction_score_2': 'class_2'}</code>.</li> </ul> <code>None</code> <code>identifier_column_name</code> <code>Optional[str]</code> <p>The name of the identifier column. Any column that heuristics identified as identifier will be changed to a feature column.</p> <code>None</code> <code>ignore_column_names</code> <code>Union[str, Collection[str]]</code> <p>The names of columns to ignore.</p> <code>()</code> <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The inspected schema with any modifications applied.</p>"},{"location":"api_reference/model_evaluation/schema/#nannyml_cloud_sdk.model_evaluation.schema.Schema.set_identifier","title":"set_identifier  <code>classmethod</code>","text":"<pre><code>set_identifier(schema: ModelSchema, column_name: str) -&gt; ModelSchema\n</code></pre> <p>Set the identifier column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the identifier column. Any column that was previously set as identifier will be changed to a feature column.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/model_evaluation/schema/#nannyml_cloud_sdk.model_evaluation.schema.Schema.set_ignored","title":"set_ignored  <code>classmethod</code>","text":"<pre><code>set_ignored(schema: ModelSchema, column_names: Union[str, Collection[str]]) -&gt; ModelSchema\n</code></pre> <p>Set one or more columns to be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_names</code> <code>Union[str, Collection[str]]</code> <p>The name of the column or columns to ignore.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/model_evaluation/schema/#nannyml_cloud_sdk.model_evaluation.schema.Schema.set_prediction_score","title":"set_prediction_score  <code>classmethod</code>","text":"<pre><code>set_prediction_score(schema: ModelSchema, column_name_or_mapping: Union[str, Dict[str, str]]) -&gt; ModelSchema\n</code></pre> <p>Set the prediction score column(s) in a schema.</p> <p>Binary classification and regression problems require a single prediction score column. Multiclass classification problems require a dictionary mapping class names to prediction score columns, e.g. <code>{'class_1': 'prediction_score_1', 'class_2': 'prediction_score_2'}</code>.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name_or_mapping</code> <code>Union[str, Dict[str, str]]</code> <p>The name of the prediction score column or a dictionary mapping class names to prediction score column names. Any existing prediction score columns will be changed to feature columns.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/model_evaluation/schema/#nannyml_cloud_sdk.model_evaluation.schema.Schema.set_target","title":"set_target  <code>classmethod</code>","text":"<pre><code>set_target(schema: ModelSchema, column_name: str) -&gt; ModelSchema\n</code></pre> <p>Set the target column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the target column. Any column that was previously set as target will be changed to a feature column.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/configuration/","title":"configuration","text":""},{"location":"api_reference/monitoring/configuration/#nannyml_cloud_sdk.monitoring.configuration.RuntimeConfiguration","title":"RuntimeConfiguration","text":"<p>Configuration of a monitoring model.</p> <p>Use the <code>get</code> method to retrieve the current configuration of a model, and the <code>set</code> method to update it. Use the <code>default</code> method to get the default configuration for a given schema and chunking.</p>"},{"location":"api_reference/monitoring/configuration/#nannyml_cloud_sdk.monitoring.configuration.RuntimeConfiguration.default","title":"default  <code>staticmethod</code>","text":"<pre><code>default(chunking: Chunking, schema: ModelSchema, has_analysis_targets: bool, nr_of_rows: Optional[int] = None) -&gt; dict[str, Any]\n</code></pre> <p>Get the default runtime configuration for a given schema and chunking.</p> <p>Parameters:</p> Name Type Description Default <code>chunking</code> <code>Chunking</code> <p>The chunking to use.</p> required <code>schema</code> <code>ModelSchema</code> <p>The schema of the model.</p> required <code>has_analysis_targets</code> <code>bool</code> <p>Whether the schema has analysis targets.</p> required <code>nr_of_rows</code> <code>Optional[int]</code> <p>The number of rows to use if chunking is 'NUMBER_OF_ROWS'.</p> <code>None</code>"},{"location":"api_reference/monitoring/configuration/#nannyml_cloud_sdk.monitoring.configuration.RuntimeConfiguration.get","title":"get  <code>staticmethod</code>","text":"<pre><code>get(model_id: int) -&gt; _RuntimeConfiguration\n</code></pre> <p>Get the runtime configuration of a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>int</code> <p>The ID of the model.</p> required"},{"location":"api_reference/monitoring/configuration/#nannyml_cloud_sdk.monitoring.configuration.RuntimeConfiguration.set","title":"set  <code>staticmethod</code>","text":"<pre><code>set(model_id: int, config: _RuntimeConfiguration)\n</code></pre> <p>Set the runtime configuration of a model.</p> <p>This method will send the updated configuration back to the server.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>int</code> <p>The ID of the model.</p> required <code>config</code> <code>_RuntimeConfiguration</code> <p>The new runtime configuration</p> required"},{"location":"api_reference/monitoring/custom_metric/","title":"custom_metric","text":""},{"location":"api_reference/monitoring/custom_metric/#nannyml_cloud_sdk.monitoring.custom_metric.CustomMetric","title":"CustomMetric","text":"<p>Class for interacting with custom metrics in NannyML Cloud.</p>"},{"location":"api_reference/monitoring/custom_metric/#nannyml_cloud_sdk.monitoring.custom_metric.CustomMetric.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(name: str, description: str, problem_type: Literal['REGRESSION'], *, loss_function: TCustomMetricSource, aggregation_function: TCustomMetricSource, lower_value_limit: Optional[float] = None, upper_value_limit: Optional[float] = None) -&gt; CustomRegressionMetricDetails\n</code></pre><pre><code>create(name: str, description: str, problem_type: Literal['BINARY_CLASSIFICATION', 'MULTICLASS_CLASSIFICATION'], *, calculation_function: TCustomMetricSource, estimation_function: Optional[TCustomMetricSource] = None, lower_value_limit: Optional[float] = None, upper_value_limit: Optional[float] = None) -&gt; CustomClassificationMetricDetails\n</code></pre> <pre><code>create(name: str, description: str, problem_type: ProblemType, calculation_function: Optional[TCustomMetricSource] = None, estimation_function: Optional[TCustomMetricSource] = None, loss_function: Optional[TCustomMetricSource] = None, aggregation_function: Optional[TCustomMetricSource] = None, lower_value_limit: Optional[float] = None, upper_value_limit: Optional[float] = None) -&gt; TCustomMetricDetails\n</code></pre> <p>Create a new custom metric.</p>"},{"location":"api_reference/monitoring/custom_metric/#nannyml_cloud_sdk.monitoring.custom_metric.CustomMetric.delete","title":"delete  <code>classmethod</code>","text":"<pre><code>delete(metric_id: str) -&gt; TCustomMetricDetails\n</code></pre> <p>Delete a custom metric.</p>"},{"location":"api_reference/monitoring/custom_metric/#nannyml_cloud_sdk.monitoring.custom_metric.CustomMetric.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(metric_id: int) -&gt; TCustomMetricDetails\n</code></pre> <p>Get details of a custom metric.</p> <p>Parameters:</p> Name Type Description Default <code>metric_id</code> <code>int</code> <p>Unique identifier of the custom metric.</p> required <p>Returns:</p> Type Description <code>TCustomMetricDetails</code> <p>Details of the custom metric.</p>"},{"location":"api_reference/monitoring/custom_metric/#nannyml_cloud_sdk.monitoring.custom_metric.CustomMetric.list","title":"list  <code>classmethod</code>","text":"<pre><code>list(name: Optional[str] = None, problem_type: Optional[ProblemType] = None) -&gt; List[CustomMetricSummary]\n</code></pre> <p>List defined custom metrics.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Optional name filter.</p> <code>None</code> <code>problem_type</code> <code>Optional[ProblemType]</code> <p>Optional problem type filter.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[CustomMetricSummary]</code> <p>List of custom metrics that match the provided filter criteria.</p>"},{"location":"api_reference/monitoring/custom_metric/#nannyml_cloud_sdk.monitoring.custom_metric.CustomMetricDetails","title":"CustomMetricDetails","text":"<p>               Bases: <code>TypedDict</code></p> <p>Details of a custom metric.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>User-defined description of the custom metric</p>"},{"location":"api_reference/monitoring/custom_metric/#nannyml_cloud_sdk.monitoring.custom_metric.CustomMetricSummary","title":"CustomMetricSummary","text":"<p>               Bases: <code>TypedDict</code></p> <p>Summary of a custom metric.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>int</code> <p>Unique identifier of the custom metric (generated by NannyML Cloud when a custom metric is created).</p> <code>name</code> <code>str</code> <p>User-defined name of the custom metric.</p> <code>problemType</code> <code>ProblemType</code> <p>Type of problem the custom metric can be applied to.</p> <code>createdAt</code> <code>datetime</code> <p>Timestamp when the model was created.</p>"},{"location":"api_reference/monitoring/enums/","title":"enums","text":""},{"location":"api_reference/monitoring/model/","title":"model","text":""},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model","title":"Model","text":"<p>Operations for working with machine learning models.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.add_analysis_data","title":"add_analysis_data  <code>classmethod</code>","text":"<pre><code>add_analysis_data(model_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add analysis data to a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added.</p> required Note <p>This method does not update existing data. It only adds new data. If you want to update existing data, use upsert_analysis_data instead.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.add_analysis_target_data","title":"add_analysis_target_data  <code>classmethod</code>","text":"<pre><code>add_analysis_target_data(model_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add (delayed) target data to a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added.</p> required Note <p>This method can only be used if the model has a target data source. If you want to add analysis data to a model without a target data source, use add_analysis_data instead.</p> Note <p>This method does not update existing data. It only adds new data. If you want to update existing data, use upsert_analysis_target_data instead.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.add_custom_metric","title":"add_custom_metric  <code>classmethod</code>","text":"<pre><code>add_custom_metric(model_id: str, metric_id: str) -&gt; None\n</code></pre> <p>Add a custom metric to a monitoring model.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(name: str, schema: ModelSchema, reference_data: pd.DataFrame, analysis_data: pd.DataFrame, key_performance_metric: PerformanceMetric, key_performance_metric_component: Optional[str] = None, target_data: Optional[pd.DataFrame] = None, chunk_period: Optional[ChunkPeriod] = None, chunk_size: Optional[int] = None) -&gt; ModelDetails\n</code></pre> <p>Create a new model.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the model.</p> required <code>schema</code> <code>ModelSchema</code> <p>Schema of the model. Typically, created using Schema.from_df.</p> required <code>reference_data</code> <code>DataFrame</code> <p>Reference data to use for the model.</p> required <code>analysis_data</code> <code>DataFrame</code> <p>Analysis data to use for the model. If the data contains targets, targets must always be provided together with analysis data.</p> required <code>key_performance_metric</code> <code>PerformanceMetric</code> <p>Key performance metric for the model.</p> required <code>key_performance_metric_component</code> <code>Optional[str]</code> <p>Optional key performance metric component for the model. This is only required if the key performance metric is a composite metric, for example the <code>CONFUSION_MATRIX</code> metric that has components like <code>true_positives</code>, <code>false_positives</code>, etc.</p> <code>None</code> <code>target_data</code> <code>Optional[DataFrame]</code> <p>Optional target data to use for the model.</p> <code>None</code> <code>chunk_period</code> <code>Optional[ChunkPeriod]</code> <p>Time period per chunk. Should only be set for time-based chunking.</p> <code>None</code> <code>chunk_size</code> <code>Optional[int]</code> <p>Number of rows per chunk. Should only be set for size-based chunking.</p> <code>None</code> <p>Returns:</p> Type Description <code>ModelDetails</code> <p>Detailed about the model once it has been created.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.delete","title":"delete  <code>classmethod</code>","text":"<pre><code>delete(model_id: str) -&gt; None\n</code></pre> <p>Delete a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model to delete.</p> required"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.delete_analysis_data","title":"delete_analysis_data  <code>classmethod</code>","text":"<pre><code>delete_analysis_data(model_id: str, data_ids: pd.DataFrame) -&gt; None\n</code></pre> <p>Delete analysis data from a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data_ids</code> <code>DataFrame</code> <p>ID's for the data to be deleted.</p> required"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.delete_analysis_target_data","title":"delete_analysis_target_data  <code>classmethod</code>","text":"<pre><code>delete_analysis_target_data(model_id: str, data_ids: pd.DataFrame) -&gt; None\n</code></pre> <p>Delete target data from a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data_ids</code> <code>DataFrame</code> <p>ID's for the data to be deleted.</p> required"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(model_id: str) -&gt; ModelDetails\n</code></pre> <p>Get details for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model to get details for.</p> required <p>Returns:</p> Type Description <code>ModelDetails</code> <p>Detailed information about the model.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.get_analysis_data_history","title":"get_analysis_data_history  <code>classmethod</code>","text":"<pre><code>get_analysis_data_history(model_id: str) -&gt; List[DataSourceEvent]\n</code></pre> <p>Get analysis data history for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <p>Returns:</p> Type Description <code>List[DataSourceEvent]</code> <p>List of events related to analysis data for the model.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.get_analysis_target_data_history","title":"get_analysis_target_data_history  <code>classmethod</code>","text":"<pre><code>get_analysis_target_data_history(model_id: str) -&gt; List[DataSourceEvent]\n</code></pre> <p>Get target data history for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <p>Returns:</p> Type Description <code>List[DataSourceEvent]</code> <p>List of events related to target data for the model.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.get_reference_data_history","title":"get_reference_data_history  <code>classmethod</code>","text":"<pre><code>get_reference_data_history(model_id: str) -&gt; List[DataSourceEvent]\n</code></pre> <p>Get reference data history for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <p>Returns:</p> Type Description <code>List[DataSourceEvent]</code> <p>List of events related to reference data for the model.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.list","title":"list  <code>classmethod</code>","text":"<pre><code>list(name: Optional[str] = None, problem_type: Optional[ProblemType] = None) -&gt; List[ModelSummary]\n</code></pre> <p>List defined models.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Optional name filter.</p> <code>None</code> <code>problem_type</code> <code>Optional[ProblemType]</code> <p>Optional problem type filter.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[ModelSummary]</code> <p>List of models that match the provided filter criteria.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.remove_custom_metric","title":"remove_custom_metric  <code>classmethod</code>","text":"<pre><code>remove_custom_metric(model_id: str, metric_id: str) -&gt; None\n</code></pre> <p>Remove a custom metric from a monitoring model.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.upsert_analysis_data","title":"upsert_analysis_data  <code>classmethod</code>","text":"<pre><code>upsert_analysis_data(model_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add or update analysis data for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added/updated.</p> required Note <p>This method compares existing data with the new data to determine which rows to update and which to add. If you are certain you are only adding new data, it is recommended to use add_analysis_data instead for better performance.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.Model.upsert_analysis_target_data","title":"upsert_analysis_target_data  <code>classmethod</code>","text":"<pre><code>upsert_analysis_target_data(model_id: str, data: pd.DataFrame) -&gt; None\n</code></pre> <p>Add or update (delayed) target data for a model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>data</code> <code>DataFrame</code> <p>Data to be added/updated.</p> required Note <p>This method can only be used if the model has a target data source. If you want to update analysis data in a model without a target data source, use upsert_analysis_data instead.</p> Note <p>This method compares existing data with the new data to determine which rows to update and which to add. If you are certain you are only adding new data, it is recommended to use add_analysis_target_data instead for better performance.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.ModelDetails","title":"ModelDetails","text":"<p>               Bases: <code>ModelSummary</code></p> <p>Detailed information about a model.</p> <p>Attributes:</p> Name Type Description <code>latestRun</code> <code>Optional[RunSummary]</code> <p>The currently active run or latest run performed for the model. This is <code>None</code> if no runs have been performed yet.</p> <code>nextRun</code> <code>Optional[RunSummary]</code> <p>The next run scheduled for the model. This is <code>None</code> if there is a run currently active.</p>"},{"location":"api_reference/monitoring/model/#nannyml_cloud_sdk.monitoring.model.ModelSummary","title":"ModelSummary","text":"<p>               Bases: <code>TypedDict</code></p> <p>Summary of a model.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier of the model (generated by NannyML Cloud when a model is created).</p> <code>name</code> <code>str</code> <p>User-defined name of the model.</p> <code>problemType</code> <code>ProblemType</code> <p>Type of problem the model is trying to solve.</p> <code>createdAt</code> <code>datetime</code> <p>Timestamp when the model was created.</p>"},{"location":"api_reference/monitoring/run/","title":"run","text":""},{"location":"api_reference/monitoring/run/#nannyml_cloud_sdk.monitoring.run.Run","title":"Run","text":"<p>Operations for running NannyML model analysis.</p>"},{"location":"api_reference/monitoring/run/#nannyml_cloud_sdk.monitoring.run.Run.trigger","title":"trigger  <code>classmethod</code>","text":"<pre><code>trigger(model_id: str) -&gt; RunSummary\n</code></pre> <p>Trigger analysis of new data for a model.</p> <p>This method starts analysis for a model. The run is scheduled to start immediately, but the function returns before the run has started. The returned summary information can be used to track the progress of the run.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>The ID of the model to run.</p> required <p>Returns:</p> Type Description <code>RunSummary</code> <p>Summary information for the newly started run.</p>"},{"location":"api_reference/monitoring/run/#nannyml_cloud_sdk.monitoring.run.RunSummary","title":"RunSummary","text":"<p>               Bases: <code>TypedDict</code></p> <p>Summary information for NannyML analysis of a model, a <code>run</code>.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the run (generated by NannyML Cloud).</p> <code>state</code> <code>RunState</code> <p>Current state of the run.</p> <code>scheduledFor</code> <code>Optional[datetime]</code> <p>Date and time the run was scheduled to start.</p> <code>startedAt</code> <code>Optional[datetime]</code> <p>Date and time the run started.</p> <code>completedAt</code> <code>Optional[datetime]</code> <p>Date and time the run completed.</p> <code>ranSuccessfully</code> <code>Optional[bool]</code> <p>Whether the run completed successfully.</p>"},{"location":"api_reference/monitoring/schema/","title":"schema","text":""},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.ModelSchema","title":"ModelSchema","text":"<p>               Bases: <code>BaseSchema</code></p> <p>Schema for a machine learning model.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema","title":"Schema","text":"<p>Operations for working with machine learning model schemas.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.from_df","title":"from_df  <code>classmethod</code>","text":"<pre><code>from_df(problem_type: Literal['BINARY_CLASSIFICATION', 'REGRESSION'], df: pd.DataFrame, target_column_name: Optional[str] = ..., timestamp_column_name: Optional[str] = ..., prediction_column_name: Optional[str] = ..., prediction_score_column_name_or_mapping: Optional[str] = ..., identifier_column_name: Optional[str] = ..., feature_columns: Dict[str, FeatureType] = ..., ignore_column_names: Union[str, Collection[str]] = ..., segment_column_names: Union[str, Collection[str]] = ...) -&gt; ModelSchema\n</code></pre><pre><code>from_df(problem_type: Literal['MULTICLASS_CLASSIFICATION'], df: pd.DataFrame, target_column_name: Optional[str] = ..., timestamp_column_name: Optional[str] = ..., prediction_column_name: Optional[str] = ..., prediction_score_column_name_or_mapping: Dict[str, str] = ..., identifier_column_name: Optional[str] = ..., feature_columns: Dict[str, FeatureType] = ..., ignore_column_names: Union[str, Collection[str]] = ..., segment_column_names: Union[str, Collection[str]] = ...) -&gt; ModelSchema\n</code></pre> <pre><code>from_df(problem_type: ProblemType, df: pd.DataFrame, target_column_name: Optional[str] = None, timestamp_column_name: Optional[str] = None, prediction_column_name: Optional[str] = None, prediction_score_column_name_or_mapping: Optional[Union[str, Dict[str, str]]] = None, identifier_column_name: Optional[str] = None, feature_columns: Dict[str, FeatureType] = {}, ignore_column_names: Union[str, Collection[str]] = (), segment_column_names: Union[str, Collection[str]] = ()) -&gt; ModelSchema\n</code></pre> <p>Create a schema from a pandas dataframe.</p> <p>Sends a sample of the dataframe to the NannyML Cloud API to inspect the schema. Heuristics are used to identify what each column represents. The schema is then modified according to the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>problem_type</code> <code>ProblemType</code> <p>The problem type of the model.</p> required <code>df</code> <code>DataFrame</code> <p>The pandas dataframe to create a schema from.</p> required <code>target_column_name</code> <code>Optional[str]</code> <p>The name of the target column. Any column that heuristics identified as target will be changed to a feature column.</p> <code>None</code> <code>timestamp_column_name</code> <code>Optional[str]</code> <p>The name of the timestamp column. Any column that heuristics identified as timestamp will be changed to a feature column.</p> <code>None</code> <code>prediction_column_name</code> <code>Optional[str]</code> <p>The name of the prediction column. Any column that heuristics identified as prediction will be changed to a feature column.</p> <code>None</code> <code>prediction_score_column_name_or_mapping</code> <code>Optional[Union[str, Dict[str, str]]]</code> <p>This parameter accepts two formats depending on problem type.</p> <ul> <li>For binary classification and regression, this should be the name of the prediction score column.</li> <li>For multiclass classification, it should be a dict mapping prediction score column names to class   names, e.g. <code>{'prediction_score_1': 'class_1', 'prediction_score_2': 'class_2'}</code>.</li> </ul> <code>None</code> <code>identifier_column_name</code> <code>Optional[str]</code> <p>The name of the identifier column. Any column that heuristics identified as identifier will be changed to a feature column.</p> <code>None</code> <code>feature_columns</code> <code>Dict[str, FeatureType]</code> <p>A dictionary specifying whether features are <code>CATEGORICAL</code> or <code>CONTINUOUS</code>. Feature columns that are not specified will retain their original type.</p> <code>{}</code> <code>ignore_column_names</code> <code>Union[str, Collection[str]]</code> <p>The names of columns to ignore.</p> <code>()</code> <code>segment_column_names</code> <code>Union[str, Collection[str]]</code> <p>The names of columns to mark as segment sources. Their values will be used to segment the data. The column will keep its original type.</p> <code>()</code> <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The inspected schema with any modifications applied.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_feature","title":"set_feature  <code>classmethod</code>","text":"<pre><code>set_feature(schema: ModelSchema, column_name: str, feature_type: FeatureType) -&gt; ModelSchema\n</code></pre> <p>Set a feature column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the feature column.</p> required <code>feature_type</code> <code>FeatureType</code> <p>Whether the feature is <code>CATEGORICAL</code> or <code>CONTINUOUS</code>.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_identifier","title":"set_identifier  <code>classmethod</code>","text":"<pre><code>set_identifier(schema: ModelSchema, column_name: str) -&gt; ModelSchema\n</code></pre> <p>Set the identifier column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the identifier column. Any column that was previously set as identifier will be changed to a feature column.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_ignored","title":"set_ignored  <code>classmethod</code>","text":"<pre><code>set_ignored(schema: ModelSchema, column_names: Union[str, Collection[str]]) -&gt; ModelSchema\n</code></pre> <p>Set one or more columns to be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_names</code> <code>Union[str, Collection[str]]</code> <p>The name of the column or columns to ignore.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_prediction","title":"set_prediction  <code>classmethod</code>","text":"<pre><code>set_prediction(schema: ModelSchema, column_name: str) -&gt; ModelSchema\n</code></pre> <p>Set the prediction column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the prediction column. Any column that was previously set as prediction will be changed to a feature column.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_prediction_score","title":"set_prediction_score  <code>classmethod</code>","text":"<pre><code>set_prediction_score(schema: ModelSchema, column_name_or_mapping: Union[str, Dict[str, str]]) -&gt; ModelSchema\n</code></pre> <p>Set the prediction score column(s) in a schema.</p> <p>Binary classification and regression problems require a single prediction score column. Multiclass classification problems require a dictionary mapping class names to prediction score columns, e.g. <code>{'class_1': 'prediction_score_1', 'class_2': 'prediction_score_2'}</code>.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name_or_mapping</code> <code>Union[str, Dict[str, str]]</code> <p>The name of the prediction score column or a dictionary mapping class names to prediction score column names. Any existing prediction score columns will be changed to feature columns.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_segment","title":"set_segment  <code>classmethod</code>","text":"<pre><code>set_segment(schema: ModelSchema, column_name: str) -&gt; ModelSchema\n</code></pre> <p>Sets the SEGMENT column flag for a column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the column to mark as a segment column. The column will keep its original type.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_target","title":"set_target  <code>classmethod</code>","text":"<pre><code>set_target(schema: ModelSchema, column_name: str) -&gt; ModelSchema\n</code></pre> <p>Set the target column in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the target column. Any column that was previously set as target will be changed to a feature column.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"},{"location":"api_reference/monitoring/schema/#nannyml_cloud_sdk.monitoring.schema.Schema.set_timestamp","title":"set_timestamp  <code>classmethod</code>","text":"<pre><code>set_timestamp(schema: ModelSchema, column_name: str) -&gt; ModelSchema\n</code></pre> <p>Set the timestamp column in a schema.</p> Note <p>The timestamp column will be coerced to a datetime data type.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The schema to modify.</p> required <code>column_name</code> <code>str</code> <p>The name of the timestamp column. Any column that was previously set as timestamp will be changed to a feature column.</p> required <p>Returns:</p> Type Description <code>ModelSchema</code> <p>The modified schema.</p>"}]}