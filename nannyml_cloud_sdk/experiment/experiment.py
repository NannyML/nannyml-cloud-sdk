import datetime
import functools
from typing import Optional, List, Dict

import pandas as pd
from gql import gql

from nannyml_cloud_sdk._typing import TypedDict
from nannyml_cloud_sdk.client import execute
from nannyml_cloud_sdk.data import DATA_SOURCE_SUMMARY_FRAGMENT, DATA_SOURCE_EVENT_FRAGMENT, Data, DataSourceSummary, \
    DataSourceFilter, DataSourceEvent
from nannyml_cloud_sdk.enums import ProblemType
from nannyml_cloud_sdk.experiment.enums import ExperimentType
from nannyml_cloud_sdk.experiment.run import RunSummary, RUN_SUMMARY_FRAGMENT
from nannyml_cloud_sdk.experiment.schema import ExperimentSchema


class ExperimentSummary(TypedDict):
    """Summary of an experiment.

    Attributes:
        id: Unique identifier of the model (generated by NannyML Cloud when a model is created).
        name: User-defined name of the model.
        createdAt: Timestamp when the model was created.
    """
    id: str
    name: str
    experimentType: ExperimentType
    createdAt: datetime.datetime


class ExperimentDetails(ExperimentSummary):
    """Detailed information about a model.

    Attributes:
        latestRun: The currently active run or latest run performed for the model. This is ``None`` if no runs have been
            performed yet.
    """

    latestRun: Optional[RunSummary]


_EXPERIMENT_SUMMARY_FRAGMENT = f"""
    fragment ExperimentSummary on Experiment {{
        {' '.join(ExperimentSummary.__required_keys__)}
    }}
"""

_EXPERIMENT_DETAILS_FRAGMENT = """
    fragment ExperimentDetails on Experiment {
        ...ExperimentSummary
        latestRun {
            ...RunSummary
        }
    }
""" + _EXPERIMENT_SUMMARY_FRAGMENT + RUN_SUMMARY_FRAGMENT

_LIST_EXPERIMENTS = gql("""
    query listExperiments($filter: ExperimentsFilter) {
        experiments(filter: $filter) {
            ...ExperimentSummary
        }
    }
""" + _EXPERIMENT_SUMMARY_FRAGMENT)

_READ_EXPERIMENT = gql("""
    query readExperiment($id: Int!) {
        experiment(id: $id) {
            ...ExperimentDetails
        }
    }
""" + _EXPERIMENT_DETAILS_FRAGMENT)

_GET_EXPERIMENT_DATA_SOURCES = gql("""
    query getExperimentDataSources($experimentId: Int!) {
        experiment(id: $experimentId) {
            dataSource{
              ...DataSourceSummary
            }
        }
    }
""" + DATA_SOURCE_SUMMARY_FRAGMENT)

_GET_EXPERIMENT_DATA_HISTORY = gql("""
    query getModelDataHistory($experimentId: Int!) {
        experiment(id: $experimentId) {
            dataSource{
                events {
                    ...DataSourceEvent
                }
                ...DataSourceSummary
            }
        }
    }
""" + DATA_SOURCE_SUMMARY_FRAGMENT + DATA_SOURCE_EVENT_FRAGMENT)


_CREATE_EXPERIMENT = gql("""
    mutation createExperiment($input: CreateExperimentInput!) {
        create_experiment(input: $input) {
            ...ExperimentDetails
        }
    }
""" + _EXPERIMENT_DETAILS_FRAGMENT)

_DELETE_EXPERIMENT = gql("""
    mutation deleteExperiment($id: Int!) {
        delete_experiment(id: $id) {
            id
        }
    }
""")

_ADD_DATA_TO_DATA_SOURCE = gql("""
    mutation addDataToDataSource($input: DataSourceDataInput!) {
        add_data_to_data_source(input: $input) {
            id
        }
    }
""")

_UPSERT_DATA_IN_DATA_SOURCE = gql("""
    mutation updateDataInDataSource($input: DataSourceDataInput!) {
        upsert_data_in_data_source(input: $input) {
            id
        }
    }
""")

_REMOVE_DATA_FROM_DATA_SOURCE = gql("""
    mutation removeDataFromDataSource($input: DataSourceDeleteInput!) {
        delete_data_from_data_source(input: $input) {
            id
        }
    }
""")


class MetricConfiguration(TypedDict):
    enabled: bool
    rope_lower_bound: Optional[float]
    rope_upper_bound: Optional[float]
    hdi_width: Optional[float]


class Experiment:

    @classmethod
    def list(
            cls, name: Optional[str] = None, problem_type: Optional[ProblemType] = None
    ) -> List[ExperimentSummary]:
        """List defined models.

        Args:
            name: Optional name filter.
            problem_type: Optional problem type filter.

        Returns:
            List of models that match the provided filter criteria.
        """
        return execute(_LIST_EXPERIMENTS, {
            'filter': {
                'name': name,
                'problemType': problem_type,
            }
        })['experiments']

    @classmethod
    def get(cls, experiment_id: str) -> ExperimentDetails:
        """Get details for a model.

        Args:
            model_id: ID of the model to get details for.

        Returns:
            Detailed information about the model.
        """
        return execute(_READ_EXPERIMENT, {'id': int(experiment_id)})['experiment']

    @classmethod
    def create(
            cls,
            schema: ExperimentSchema,
            experiment_data: pd.DataFrame,
            experiment_type: ExperimentType,
            metrics_configuration: Dict[str, MetricConfiguration],
            name: Optional[str] = None,
            key_experiment_metric: Optional[str] = None,
    ) -> ExperimentDetails:
        """Create a new model.

        Args:
            schema: Schema of the model. Typically created using [Schema.from_df][nannyml_cloud_sdk.Schema.from_df].
            reference_data: Reference data to use for the model.
            evaluation_data: Analysis data to use for the model. If the data contains targets, targets must always be
                provided together with analysis data.
            name: Optional name for the model. If not provided, a name will be generated.
            main_performance_metric: Optional main performance metric for the model. If not provided, no performance
                metric will be tagged as main.

        Returns:
            Detailed about the model once it has been created.
        """

        data_source = {
            'name': 'experiment',
            'hasReferenceData': False,
            'hasAnalysisData': True,
            'columns': schema['columns'],
            'storageInfo': Data.upload(experiment_data),
        }

        return execute(_CREATE_EXPERIMENT, {
            'input': {
                'name': name,
                'experimentType': experiment_type,
                'dataSource': data_source,
                'kem': key_experiment_metric,
                'config': {
                    'metrics': [{
                        'metric': metric,
                        'enabled': config['enabled'],
                        'ropeLowerBound': config['rope_lower_bound'],
                        'ropeUpperBound': config['rope_upper_bound'],
                        'hdiWidth': config['hdi_width'],
                    } for metric, config in metrics_configuration.items()]
                }
            },
        })['create_experiment']

    @classmethod
    def delete(cls, experiment_id: str) -> None:
        """Delete a model.

        Args:
            model_id: ID of the model to delete.
        """
        execute(_DELETE_EXPERIMENT, {'id': int(experiment_id)})

    @classmethod
    def add_evaluation_data(cls, experiment_id: str, data: pd.DataFrame) -> None:
        """Add evaluation data to a model.

        Args:
            model_id: ID of the model.
            data: Data to be added.

        Note:
            This method does not update existing data. It only adds new data. If you want to update existing data,
            use [upsert_analysis_data][nannyml_cloud_sdk.Model.upsert_analysis_data] instead.
        """
        data_source = cls._get_experiment_data_source(experiment_id)
        execute(_ADD_DATA_TO_DATA_SOURCE, {
            'input': {
                'id': int(data_source['id']),
                'storageInfo': Data.upload(data),
            },
        })

    @classmethod
    def upsert_evaluation_data(cls, experiment_id: str, data: pd.DataFrame) -> None:
        """Add or update analysis data for a model.

        Args:
            model_id: ID of the model.
            data: Data to be added/updated.

        Note:
            This method compares existing data with the new data to determine which rows to update and which to add.
            If you are certain you are only adding new data, it is recommended to use
            [add_analysis_data][nannyml_cloud_sdk.Model.add_analysis_data] instead for better performance.
        """
        data_source = cls._get_experiment_data_source(experiment_id)
        execute(_UPSERT_DATA_IN_DATA_SOURCE, {
            'input': {
                'id': int(data_source['id']),
                'storageInfo': Data.upload(data),
            },
        })

    @classmethod
    def get_data_history(cls, experiment_id: str) -> List[DataSourceEvent]:
        """Get reference data history for a model.

        Args:
            model_id: ID of the model.

        Returns:
            List of events related to reference data for the model.
        """
        return execute(_GET_EXPERIMENT_DATA_HISTORY, {
            'modelId': int(experiment_id),
        })['evaluation_model']['referenceDataSource']['events']

    @staticmethod
    @functools.lru_cache(maxsize=128)
    def _get_experiment_data_source(
            model_id: str, filter: Optional[DataSourceFilter] = None
    ) -> DataSourceSummary:
        """Get data sources for a model"""
        return execute(_GET_EXPERIMENT_DATA_SOURCES, {
            'modelId': int(model_id),
            'filter': filter,
        })['experiment']['dataSource']
